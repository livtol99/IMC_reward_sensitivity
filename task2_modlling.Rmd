---
title: "Models"
author: "Liv Toll√•nes"
date: "2023-02-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## 2. Multilevel modelling of reward anticipation and self reports of pleasure and experience of reward
Q: Does lab-measured reward anticipation (averaged EEfRT scores) predict self-reported (i) "anticipated reward pleasure" (ii) "experienced reward" in the real world (ESM)? 


	- Use the averaged EEfRT scores created in task 1. (Scores from the 2 days(pos and neg) merged together, but with 3 levels, low, med, high probability)
	
	- Use multilevel modelling, with 3 levels of nested data (questionnaires, nested within days, within participants)
	
	- The analysis would be very close to the paper: https://psyarxiv.com/fnhd9/, but with EEfRT performance as the participant-level predictors (low, med, high) instead of the ISI, RPA scores, and ERQ scores. The EEfRT are obviously not day-level predictors, but more like our covariates baseline, ISI  - instead of baseline participant-level ISI scores, RPA scores, and ERQ scores). "Participant" and "Days within participant" are random intercepts.


```{r}
#Loading packages 

pacman::p_load("tidyverse", "ggpubr", "Hmisc", "corrplot", "rstatix", "psych", "nlme", "lme4", "lmerTest", "JWileymisc","multilevelTools", "texreg")


```

```{r}
#Loading ESM data

ESM <- read.csv("./data/ESM_reduced.csv")
ESM_keys <- read.csv("./data/ESM_keys.csv")

unique(ESM$Actual_ID) # P022 was never there from the beginning

### Removing the excluded rows for low participation

#Are there still 2-s in the column?
ESM$Excluded.for.Low.Participation..1...no..2...yes. <-  as.factor(ESM$Excluded.for.Low.Participation..1...no..2...yes.)
is.factor(ESM$Excluded.for.Low.Participation..1...no..2...yes.)
unique(ESM$Excluded.for.Low.Participation..1...no..2...yes.)

# keeping an overview of what participants were removed - for matching with the CBM df
ESM_exluded_low_part <- filter(ESM, Excluded.for.Low.Participation..1...no..2...yes. == "2")
ESM_exluded_low_part_ID <- unique(ESM_exluded_low_part$Actual_ID) #The IDs removed are P010, P019, P020, P028, P038, P041, P049, P506, P513

#Removing from main df
ESM <- filter(ESM, Excluded.for.Low.Participation..1...no..2...yes. != "2")
unique(ESM$Excluded.for.Low.Participation..1...no..2...yes.)

length(unique(ESM$Actual_ID)) #There are 67 unique participants in this df



##############################
#CBM data set
CBM <- read.csv("./data/preprocessed.csv")
CBM_vars <- read.csv("./data/CBM_variables.csv")

length(unique(CBM$ID)) #There are 79 unique IDs - 12 more than in the ESM data

#Replace weird column values with NA
CBM[CBM  == "#NULL!"] <- NA


#Selecting only the relevant columns in the CBM data for better overview
CBM_sub <- CBM %>% select(c(1:7), 
                          EEfRT_averaged_lowp, 
                          EEfRT_averaged_medp, 
                          EEfRT_averaged_highp,
                          EEfRT_LowProb_DiffScore,
                          EEfRT_MedProb_DiffScore,
                          EEfRT_HighProb_DiffScore,
                          POSCBMTrainingaccuracy,	
                          POSCBMTestingaccuracy,
                          NEGCBMTrainingaccuracy,
                          NEGCBMTestingaccuracy,
                          RT_POS_TRAINING_IDX,
                          RT_NEG_TRAINING_IDX,
                          RT_Diff_Score,
                          TEPS_ANT, TEPS_CON, MASQ_AA, MASQ_GD, MASQ_AD,  BAS_Drive, BAS_FS,BAS_RR, BIS)

CBM_sub$exclude <- NULL
CBM_sub$participant_id <- NULL

# 16 participants have NAs in their EEfRT columns - due to lacking EEfRT scores

#Removing the participants not included in the ESM df first to inspect what IDs are left
CBM_sub <- filter(CBM_sub, ID != "P010")
CBM_sub <- filter(CBM_sub, ID != "P019")
CBM_sub <- filter(CBM_sub, ID != "P020")
CBM_sub <- filter(CBM_sub, ID != "P028")
CBM_sub <- filter(CBM_sub, ID != "P038")
CBM_sub <- filter(CBM_sub, ID != "P041")
CBM_sub <- filter(CBM_sub, ID != "P049")
CBM_sub <- filter(CBM_sub, ID != "P506")
CBM_sub <- filter(CBM_sub, ID != "P513")

length(unique(CBM_sub$ID)) #Length is now 70, but 12 problematic participants are left. Only 4 of those removed were NA-participants

# Looking into the original df for these participants - what is the issue?
#The problematic IDs are: P003, P024, P036, P501, P509, P510, P512, P515, P525, P526, P535, P536
probID <- subset(CBM, ID %in% c("P003", "P024", "P036", "P501", "P509", "P510", "P512", "P515", "P525", "P526", "P535", "P536"))


#Further inspection shows that the problematic IDs are caused by NAs in the various prob categories of the EEfRT measurements - so incomplete CBM data. Removing all of them
CBM_sub <- CBM_sub %>% filter(!ID %in% c("P003", "P024", "P036", "P501", "P509", "P510","P512", "P515", "P525", "P526", "P535", "P536")) #The resulting df 


#Unique IDs in the subsetted CBM data
length(unique(CBM_sub$ID)) #The resulting df now has 58 unique participants. There were 67 in the ESM data. 
CBM_sub_unique_IDs <- unique(CBM_sub$ID)

#Looking at which IDS in the ESM df do not occur in the CBM df
unique(ESM$Actual_ID)

unique(CBM_sub$ID)

#The IDs that occur in the ESM data but not in the CBM data are:
#P024, P036, P501, P509, P512, P525, P526, P535, P536 (9 in total)
#Removing them from the ESM data:
ESM <- ESM %>% filter(!Actual_ID %in% c("P003","P024", "P036", "P501", "P509", "P512", "P525", "P526", "P535", "P536"))

unique(ESM$Actual_ID)

unique(CBM_sub$ID)

#P022 is in CBM sub - but was never there for ESM. Removing P022 from CBM_sub
CBM_sub <- CBM_sub %>% filter(!ID %in% "P022")

length(unique(ESM$Actual_ID))
length(unique(CBM_sub$ID)) #The two dfs are now equal 




##### Instead of all of the above, I guess an alternative option was to just merge the dfs, and write na.action "na-omit" in the model .....
```



```{r}
#The next task is to add three EEfRT columns to the ESM data frame, replicating their scores across each row every partipant has
#Rename Actual_ID in ESM df to ID
ESM <- ESM %>% rename(ID = Actual_ID)

#Creating a merged column of subject and day
ESM$subj_day <- paste(ESM$ID, ESM$Day)

#Merging the two dfs
ESM_merged <- merge(ESM, CBM_sub, all.x=TRUE, by="ID")
ESM_merged <- as_tibble(ESM_merged)

#reordering columns for better overview
ESM_merged <- ESM_merged  %>% relocate(subj_day, .after=Day)
ESM_merged <- ESM_merged  %>% relocate(Excluded.for.Low.Participation..1...no..2...yes., .after=BIS)
ESM_merged <- ESM_merged  %>% relocate(StartDate, .after=Excluded.for.Low.Participation..1...no..2...yes.)
ESM_merged <- ESM_merged  %>% relocate(Nationality, .after=StartDate)


mergeddf <- write.csv(ESM_merged, "./data/ESM_CBM_merged")

```

## Actual modelling

Variable types:
- Outcome/dependent variables (ant/con. pleasure) are ordinal (measured on 7 pt. Likert scale)
- Predictors: EEfRT averages are ratios. Between 0 and 1


I should consider centering the outcome variables (ant/con pleasure - see link: https://philippmasur.de/2018/05/23/how-to-center-in-multilevel-models/)

Christine writes that the multilevel analysis should contain:
- checking residuals
- mean-centring some variables
- running models (with and without outliers)
- generating some plots at the end


# Inspecting the distributions of the data (once more :PPP)
```{r}
#Distribution of experienced and anticipated pleasure scores
hist(ESM_merged$AntPleasure, col = 'coral2')
hist(ESM_merged$ConPleasure, col = 'steelblue')


#Looking into exact summaries per pleasure score 
# The total distributions are very even across the two measures
Ant_pl <- ESM_merged %>%
  group_by(AntPleasure) %>%
  summarise(counts = n())

Con_pl <- ESM_merged %>%
  group_by(ConPleasure) %>%
  summarise(counts = n())


Ant_pl
Con_pl


#Distribution of proportions according to reward probability 
hist(ESM_merged$EEfRT_averaged_lowp, col = 'coral2') # When the probability of reward is low, the general tendency is for people to not make very much effort (low proportions of people chose the hard task)
hist(ESM_merged$EEfRT_averaged_medp, col = 'green') # When the probability of reward is medium, there is a tendency that 50/50 chooses either the hard or the low task
hist(ESM_merged$EEfRT_averaged_highp, col = 'blue') #When the probability of reward is high, there is a tendency that most people choose the hard task


#Relationship between the two outcome variables - Are they correlated? (Colour by ID or Day)
ggplot(ESM_merged, aes(x=AntPleasure, y=ConPleasure, colour = ID)) + geom_point() + geom_jitter() #Inspection of the plot shows us that the two outcome measures most likely are correlated, with the spread of scores also being equal to each side from the midline. Seems to be relatively even across participants and days


#Are the predictors correlated?
ggplot(ESM_merged, aes(x=EEfRT_averaged_medp, y=EEfRT_averaged_lowp, colour = ID)) + geom_point()
ggplot(ESM_merged, aes(x=EEfRT_averaged_medp, y=EEfRT_averaged_highp, colour = ID)) + geom_point() 
ggplot(ESM_merged, aes(x=EEfRT_averaged_lowp, y=EEfRT_averaged_highp, colour = ID)) + geom_point() 

ggplot(ESM_merged, aes(EEfRT_averaged_medp, EEfRT_averaged_lowp)) + 
  geom_point(color='blue') +
  geom_smooth(method = "lm", colour = 'red')


ggplot(ESM_merged, aes(EEfRT_averaged_medp, EEfRT_averaged_highp)) + 
  geom_point(color='blue') +
  geom_smooth(method = "lm", colour = 'red')

ggplot(ESM_merged, aes(EEfRT_averaged_highp, EEfRT_averaged_lowp)) + 
  geom_point(color='blue') +
  geom_smooth(method = "lm", colour = 'red')

# #From long to wide data
library(tidyr)
wide <- ESM_merged %>% pivot_longer(cols=c('EEfRT_averaged_lowp', 'EEfRT_averaged_medp', 'EEfRT_averaged_highp'),
                    names_to='prob_cond',
                    values_to='Hard_task_proportion')


#Add new column with dummy variables for the probability condition
# Create dummy variables for 2 columns
wide$dummy_prob_group <- NA
wide$dummy_prob_group[wide$prob_cond == "EEfRT_averaged_lowp"] <- 1
wide$dummy_prob_group[wide$prob_cond == "EEfRT_averaged_medp"] <- 2
wide$dummy_prob_group[wide$prob_cond == "EEfRT_averaged_highp"] <- 3

unique(wide$dummy_prob_group)


# Create a line plot with all conditions in one - to see pattern differences
ggplot(wide, aes(x = dummy_prob_group, y = Hard_task_proportion, color = ID)) + geom_line() +
  scale_x_continuous(breaks = seq(1, 3, by = 1))


# Inspect the distribution of anticipated pleasure and experienced pleasure across days for each participant
ggplot(ESM_merged, aes(x = AntPleasure, color = ID)) + geom_jitter(stat="count") +
  scale_x_continuous(breaks = seq(1, 7, by = 1)) + facet_wrap(~Day) + labs(title = "Anticipated Pleasure",
       subtitle = "(Visualised per day of measurement across IDs)", y = "Count", x = "Anticipated Pleasure - 7 pt. Likert Scale") + 
  theme_bw() + theme(legend.position="none")


ggplot(ESM_merged, aes(x = ConPleasure, color = ID)) + geom_jitter(stat="count") +
  scale_x_continuous(breaks = seq(1, 7, by = 1)) + facet_wrap(~Day) + labs(title = "Experienced Pleasure",
       subtitle = "(Visualised per day of measurement)",
       y = "Count", x = "Anticipated Pleasure - 7 pt. Likert Scale") + theme_bw() + theme(legend.position="none")

#These plot shows an indication that the response pattern does not vary much between days. The same response pattern is found between the two pleasure measures, with a tendency for all participants to have more responses in the positive end of the Likert-scale. (5-7)


#Centering and scaling the two outcome variables
#Adding a z-score column to the data frame for the pleasure scores (scaling)
ESM_merged$ConPleasure_Z <- scale(ESM_merged$ConPleasure, center = T, scale = T)
ESM_merged$AntPleasure_Z <- scale(ESM_merged$AntPleasure, center = T, scale = T)

#Mean-Centering the outcome variables
ESM_merged$ConPleasure_centered <- scale(ESM_merged$ConPleasure, center = T, scale = F)
ESM_merged$AntPleasure_centered <- scale(ESM_merged$AntPleasure, center = T, scale = F)

#Visualising the z-scored and centered outcome variables as distributions per participant

ggplot(ESM_merged, aes(ConPleasure)) + geom_density(aes(x=ConPleasure, y=..density.., color = ID), bins=50) + facet_wrap(~ID) + theme(legend.position="none") + ggtitle("Experienced Pleasure - Uncentered") + scale_x_continuous(breaks = seq(1, 7, by = 1))

ggplot(ESM_merged, aes(ConPleasure_Z)) + geom_density(aes(x=ConPleasure_Z, y=..density.., color = ID), bins=50) + facet_wrap(~ID) + theme(legend.position="none") + ggtitle("Experienced Pleasure - Z-scored") 

ggplot(ESM_merged, aes(ConPleasure_centered)) + geom_density(aes(x=ConPleasure_centered, y=..density.., color = ID), bins=50) + facet_wrap(~ID) + theme(legend.position="none")+ ggtitle("Experienced Pleasure - Population Mean Centered") 

```


```{r}
#Inspecting range of EEfRT ratios (predictors)
min(ESM_merged$EEfRT_averaged_lowp) #0
max(ESM_merged$EEfRT_averaged_lowp) #0.81

min(ESM_merged$EEfRT_averaged_medp) #0
max(ESM_merged$EEfRT_averaged_medp) #0.975

min(ESM_merged$EEfRT_averaged_highp) #0.03
max(ESM_merged$EEfRT_averaged_highp) #0.1


```

#Modelling

#Linear regression:
For linear regression to work in this context, The outcome variable of daily life reward anticipation (ant_ or con_pleasure) must be in a continuous format. As of now, these variables are ordinal. The question is then if it makes sense to mean transform these scores. If not, it is worth considering a different modeling approach, such a cumulative link model (mixed effects logistic regression)

- LinReg uses a linear equation to identify the line of best fit - and thereby enables prediction of the output of the dependent variable based on the independent ones. 
- lInear regression describes a linear relationship between variables
- In this study, the question is thus: how are lab measures of reward anticipation linearly related to real life measures of the same?
- Linear regression requires a continuous outcome variable - our outcome variable is not continuous unless we transform it to be so
- calculates coefficients/estimates best fitting regression line through ordinary least squares

# Logistic regression 
A logistic regression is used to classify/predict a categorical (usually binary) outcome  based on previous observations of a data set. Independent variables are used to predict the occurrence or failure of specific events. Standard Logistic regression‚Äôs output lies between 0 and 1.

- Logistic regression seeks to study and examine the probabilities of an event's occurrence.
- In our case, the outcome variable is not binary, and so a standard logistic regression is not suitable. 
- Calculates coefficients through maximum likelihood estimation


The fact that I am asked to answer whether the lab measures of reward anticipation can predict the ESM measures of reward anticipation seems kind of strange, when really the power point seems to suggest that the question of interest really regards wether or not the two are associated with each other. 


Cumulative link model
This is a logistic regression model - and the task is becoming a classification task rather than a prediction task. 
```{r}
# I do not think centering the predictors is necessary - there is a true meaningful 0 (our predictors are ratio variables)

#simply fitting the models to see what we've got 
# No centering, no residual checks, and treating the outcome as continuous (not doing an ordinal regression)

test_ant_pl <- lmer(AntPleasure ~ EEfRT_averaged_lowp + EEfRT_averaged_medp + EEfRT_averaged_highp + (1|subj_day) + (1|ID), data = ESM_merged, REML = FALSE, na.action = "na.omit")


?lmer

test_con_pl <- lmer(ConPleasure ~ EEfRT_averaged_lowp + EEfRT_averaged_medp + EEfRT_averaged_highp + (1|subj_day) + (1|ID),  
                        data = ESM_merged, REML = FALSE, na.action = "na.omit")

summary(test_ant_pl)
summary(test_con_pl)



#Cannot use linear regression since our outcome measure really isn't continuous
#Should rather do ordinal logistic regression



#Centering predictors - tetsing the same models but with centered predictors
ESM_merged$EEfRT_averaged_lowp_cen <- scale(ESM_merged$EEfRT_averaged_lowp, center = TRUE, scale = FALSE)
ESM_merged$EEfRT_averaged_medp_cen <- scale(ESM_merged$EEfRT_averaged_medp, center = TRUE, scale = FALSE)
ESM_merged$EEfRT_averaged_highp_cen <- scale(ESM_merged$EEfRT_averaged_highp, center = TRUE, scale = FALSE)

test_ant_cen <- lmer(AntPleasure ~ EEfRT_averaged_lowp_cen + EEfRT_averaged_medp_cen + EEfRT_averaged_highp_cen + (1|subj_day) + (1|ID), data = ESM_merged, REML = FALSE, na.action = "na.omit")


test_con_cen <- lmer(ConPleasure ~ EEfRT_averaged_lowp_cen + EEfRT_averaged_medp_cen + EEfRT_averaged_highp_cen + (1|subj_day) + (1|ID), data = ESM_merged, REML = FALSE, na.action = "na.omit")


summary(test_ant_cen)
summary(test_con_cen)
summary(test_con_pl)


#Testing cumulative link mixed models (haven't checked assumptions yet)


# plot distributions
d %>% 
  gather(Variable, val, c("x", "x.c")) %>%
  ggplot(aes(x = val, group = Variable, fill = Variable)) + 
  geom_density(alpha = .4) + 
  labs(x = "Variable X" , y = "Count") +
  geom_vline(xintercept = mean(d$x),
             linetype = "dashed") +
  geom_vline(xintercept = mean(d$x.c),
             linetype = "dashed") +
  xlim(-1.5, 4) +
  labs(x = "" , y = "Count") +
  theme_classic()

```

#Assumptions of linear regression
The assumptions, for a linear mixed effects model,
‚Ä¢ The explanatory variables are related linearly to the response.
‚Ä¢ The residuals have constant variance (homogeneity of variance)
‚Ä¢ The residuals are Normally distributed.
‚Ä¢ The residuals are independent.

```{r}

#Linearity between predictors and outcome variable
#This can be checked by plotting the residuals against the response and looking for any systematic shape, and by including non-linear terms (or splines) and comparing the model fit.


#Testing assumptions
#Normal residuals
## extract residuals:
res_ant <- residuals(test_ant_pl)
qqnorm(res_ant)
abline(0,1)
hist(res_ant)


res_con <- residuals(test_con_pl)
qqnorm(res_ant)
abline(0,1)
hist(res_con)


# So far, residuals don't look normal. Might have to transform data (still considering using a different model)



# 2. homogeneity of variance (violated - there is a clear pattern)
# The residuals have constant variance. This can be checked with a plot of residuals against fitted values - there should be no pattern/trend.
plot(fitted(test_ant_pl), res_ant)
abline(0,0) #add a horizontal line at 0 


#3. Normally distributed residuals
#This can be checked in many ways, such as a Q-Q plot and a simple histogram. Statistical tests, such as Anderson-Darling and Kolmogorov‚ÄìSmirnov are also possible.

#4. Independent residuals
#This can be checked by plotting residuals against covariates - especially time-varying or spatial covariates. There should not be any systematic pattern








```


#Testing out ordinal linear regression
```{r}

```












