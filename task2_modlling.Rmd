---
title: "Models"
author: "Liv Toll√•nes"
date: "2023-02-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## 2. Multilevel modelling of reward anticipation and self reports of pleasure and experience of reward
Q: Does lab-measured reward anticipation (averaged EEfRT scores) predict self-reported (i) "anticipated reward pleasure" (ii) "experienced reward" in the real world (ESM)? 


	- Use the averaged EEfRT scores created in task 1. (Scores from the 2 days(pos and neg) merged together, but with 3 levels, low, med, high probability)
	
	- Use multilevel modelling, with 3 levels of nested data (questionnaires, nested within days, within participants)
	
	- The analysis would be very close to the paper: https://psyarxiv.com/fnhd9/, but with EEfRT performance as the participant-level predictors (low, med, high) instead of the ISI, RPA scores, and ERQ scores. The EEfRT are obviously not day-level predictors, but more like our covariates baseline, ISI  - instead of baseline participant-level ISI scores, RPA scores, and ERQ scores). "Participant" and "Days within participant" are random intercepts.


```{r}
#Loading packages 

pacman::p_load("tidyverse", "ggpubr", "Hmisc", "corrplot", "rstatix", "psych", "nlme", "lme4", "lmerTest", "JWileymisc","multilevelTools", "texreg")


```

```{r}
#Loading ESM data

ESM <- read.csv("./data/ESM_reduced.csv")
ESM_keys <- read.csv("./data/ESM_keys.csv")

unique(ESM$Actual_ID) # P022 was never there from the beginning

### Removing the excluded rows for low participation

#Are there still 2-s in the column?
ESM$Excluded.for.Low.Participation..1...no..2...yes. <-  as.factor(ESM$Excluded.for.Low.Participation..1...no..2...yes.)
is.factor(ESM$Excluded.for.Low.Participation..1...no..2...yes.)
unique(ESM$Excluded.for.Low.Participation..1...no..2...yes.)

# keeping an overview of what participants were removed - for matching with the CBM df
ESM_exluded_low_part <- filter(ESM, Excluded.for.Low.Participation..1...no..2...yes. == "2")
ESM_exluded_low_part_ID <- unique(ESM_exluded_low_part$Actual_ID) #The IDs removed are P010, P019, P020, P028, P038, P041, P049, P506, P513

#Removing from main df
ESM <- filter(ESM, Excluded.for.Low.Participation..1...no..2...yes. != "2")
unique(ESM$Excluded.for.Low.Participation..1...no..2...yes.)

length(unique(ESM$Actual_ID)) #There are 67 unique participants in this df



##############################
#CBM data set
CBM <- read.csv("./data/preprocessed.csv")
CBM_vars <- read.csv("./data/CBM_variables.csv")

length(unique(CBM$ID)) #There are 79 unique IDs - 12 more than in the ESM data

#Replace weird column values with NA
CBM[CBM  == "#NULL!"] <- NA


#Selecting only the relevant columns in the CBM data for better overview
CBM_sub <- CBM %>% select(c(1:7), 
                          EEfRT_averaged_lowp, 
                          EEfRT_averaged_medp, 
                          EEfRT_averaged_highp,
                          EEfRT_LowProb_DiffScore,
                          EEfRT_MedProb_DiffScore,
                          EEfRT_HighProb_DiffScore,
                          POSCBMTrainingaccuracy,	
                          POSCBMTestingaccuracy,
                          NEGCBMTrainingaccuracy,
                          NEGCBMTestingaccuracy,
                          RT_POS_TRAINING_IDX,
                          RT_NEG_TRAINING_IDX,
                          RT_Diff_Score,
                          TEPS_ANT, TEPS_CON, MASQ_AA, MASQ_GD, MASQ_AD,  BAS_Drive, BAS_FS,BAS_RR, BIS)

CBM_sub$exclude <- NULL
CBM_sub$participant_id <- NULL

# 16 participants have NAs in their EEfRT columns - due to lacking EEfRT scores

#Removing the participants not included in the ESM df first to inspect what IDs are left
CBM_sub <- filter(CBM_sub, ID != "P010")
CBM_sub <- filter(CBM_sub, ID != "P019")
CBM_sub <- filter(CBM_sub, ID != "P020")
CBM_sub <- filter(CBM_sub, ID != "P028")
CBM_sub <- filter(CBM_sub, ID != "P038")
CBM_sub <- filter(CBM_sub, ID != "P041")
CBM_sub <- filter(CBM_sub, ID != "P049")
CBM_sub <- filter(CBM_sub, ID != "P506")
CBM_sub <- filter(CBM_sub, ID != "P513")

length(unique(CBM_sub$ID)) #Length is now 70, but 12 problematic participants are left. Only 4 of those removed were NA-participants

# Looking into the original df for these participants - what is the issue?
#The problematic IDs are: P003, P024, P036, P501, P509, P510, P512, P515, P525, P526, P535, P536
probID <- subset(CBM, ID %in% c("P003", "P024", "P036", "P501", "P509", "P510", "P512", "P515", "P525", "P526", "P535", "P536"))


#Further inspection shows that the problematic IDs are caused by NAs in the various prob categories of the EEfRT measurements - so incomplete CBM data. Removing all of them
CBM_sub <- CBM_sub %>% filter(!ID %in% c("P003", "P024", "P036", "P501", "P509", "P510","P512", "P515", "P525", "P526", "P535", "P536")) #The resulting df 


#Unique IDs in the subsetted CBM data
length(unique(CBM_sub$ID)) #The resulting df now has 58 unique participants. There were 67 in the ESM data. 
CBM_sub_unique_IDs <- unique(CBM_sub$ID)

#Looking at which IDS in the ESM df do not occur in the CBM df
unique(ESM$Actual_ID)

unique(CBM_sub$ID)

#The IDs that occur in the ESM data but not in the CBM data are:
#P024, P036, P501, P509, P512, P525, P526, P535, P536 (9 in total)
#Removing them from the ESM data:
ESM <- ESM %>% filter(!Actual_ID %in% c("P003","P024", "P036", "P501", "P509", "P512", "P525", "P526", "P535", "P536"))

unique(ESM$Actual_ID)

unique(CBM_sub$ID)

#P022 is in CBM sub - but was never there for ESM. Removing P022 from CBM_sub
CBM_sub <- CBM_sub %>% filter(!ID %in% "P022")

length(unique(ESM$Actual_ID))
length(unique(CBM_sub$ID)) #The two dfs are now equal 




##### Instead of all of the above, I guess an alternative option was to just merge the dfs, and write na.action "na-omit" in the model .....
```



```{r}
#The next task is to add three EEfRT columns to the ESM data frame, replicating their scores across each row every partipant has
#Rename Actual_ID in ESM df to ID
ESM <- ESM %>% rename(ID = Actual_ID)

#Creating a merged column of subject and day
ESM$subj_day <- paste(ESM$ID, ESM$Day)

#Merging the two dfs
ESM_merged <- merge(ESM, CBM_sub, all.x=TRUE, by="ID")
ESM_merged <- as_tibble(ESM_merged)

#reordering columns for better overview
ESM_merged <- ESM_merged  %>% relocate(subj_day, .after=Day)
ESM_merged <- ESM_merged  %>% relocate(Excluded.for.Low.Participation..1...no..2...yes., .after=BIS)
ESM_merged <- ESM_merged  %>% relocate(StartDate, .after=Excluded.for.Low.Participation..1...no..2...yes.)
ESM_merged <- ESM_merged  %>% relocate(Nationality, .after=StartDate)


mergeddf <- write.csv(ESM_merged, "./data/ESM_CBM_merged")

```

## Actual modelling

Variable types:
- Outcome/dependent variables (ant/con. pleasure) are ordinal (measured on 7 pt. Likert scale)
- Predictors: EEfRT averages are ratios. Between 0 and 1


I should consider centering the outcome variables (ant/con pleasure - see link: https://philippmasur.de/2018/05/23/how-to-center-in-multilevel-models/)

Christine writes that the multilevel analysis should contain:
- checking residuals
- mean-centring some variables
- running models (with and without outliers)
- generating some plots at the end


# Inspecting the distributions of the data (once more :PPP)
```{r}
#Distribution of experienced and anticipated pleasure scores
hist(ESM_merged$AntPleasure, col = 'coral2')
hist(ESM_merged$ConPleasure, col = 'steelblue')


#Looking into exact summaries per pleasure score 
# The total distributions are very even across the two measures
Ant_pl <- ESM_merged %>%
  group_by(AntPleasure) %>%
  summarise(counts = n())

Con_pl <- ESM_merged %>%
  group_by(ConPleasure) %>%
  summarise(counts = n())


Ant_pl
Con_pl


#Distribution of proportions according to reward probability 
hist(ESM_merged$EEfRT_averaged_lowp, col = 'coral2') # When the probability of reward is low, the general tendency is for people to not make very much effort (low proportions of people chose the hard task)
hist(ESM_merged$EEfRT_averaged_medp, col = 'green') # When the probability of reward is medium, there is a tendency that 50/50 chooses either the hard or the low task
hist(ESM_merged$EEfRT_averaged_highp, col = 'blue') #When the probability of reward is high, there is a tendency that most people choose the hard task


#Relationship between the two outcome variables - Are they correlated? (Colour by ID or Day)
ggplot(ESM_merged, aes(x=AntPleasure, y=ConPleasure, colour = ID)) + geom_point() + geom_jitter() #Inspection of the plot shows us that the two outcome measures most likely are correlated, with the spread of scores also being equal to each side from the midline. Seems to be relatively even across participants and days

# Plotting relationship between Con Pleasure/Ant pleasure and the three probability scores, varying according to the participants


# #From long to wide data
library(tidyr)
wide <- ESM_merged %>% pivot_longer(cols=c('EEfRT_averaged_lowp', 'EEfRT_averaged_medp', 'EEfRT_averaged_highp'),
                    names_to='prob_cond',
                    values_to='Hard_task_proportion')

wide$dummy_probability <- with(wide, ifelse(scored > allowed, 'Win', 'Loss'))

#Add new column with dummy variables for the probability condition
# Create dummy variables for 2 columns
wide$dummy_prob_group <- NA
wide$dummy_prob_group[wide$prob_cond == "EEfRT_averaged_lowp"] <- 1
wide$dummy_prob_group[wide$prob_cond == "EEfRT_averaged_medp"] <- 2
wide$dummy_prob_group[wide$prob_cond == "EEfRT_averaged_highp"] <- 3

unique(wide$dummy_prob_group)


# Create a line plot with all conditions in one - to see pattern differences
ggplot(wide, aes(x = dummy_prob_group, y = Hard_task_proportion, color = ID)) + geom_line() +
  scale_x_continuous(breaks = seq(1, 3, by = 1))


# Inspect the distribution of anticipated pleasure and experienced pleasure across days for each participant
ggplot(wide, aes(x = Day, y = AntPleasure, color = ID)) + geom_line() +
  scale_x_continuous(breaks = seq(1, 3, by = 1))

#If  the variables are correlated (so if the proportion of hard task is correlated with the probability condition) - this is an indication of whether or not we should keep the model as they want it to

```


```{r}
#Inspecting range of EEfRT ratios (predictors)
min(ESM_merged$EEfRT_averaged_lowp) #0
max(ESM_merged$EEfRT_averaged_lowp) #0.81

min(ESM_merged$EEfRT_averaged_medp) #0
max(ESM_merged$EEfRT_averaged_medp) #0.975

min(ESM_merged$EEfRT_averaged_highp) #0.03
max(ESM_merged$EEfRT_averaged_highp) #0.1


```


```{r}
#simply fitting the models to see what we've got 
# No centering, no residual checks, and treating the outcome as continuous (not doing an ordinal regression)

test_ant_pl <- lmer(AntPleasure ~ EEfRT_averaged_lowp + EEfRT_averaged_medp + EEfRT_averaged_highp + (1|subj_day) + (1|ID),  
                        data = ESM_merged, 
                        REML = FALSE, 
                        na.action = "na.omit", 
                        control = lmerControl(optimizer = "bobyqa"))

test_con_pl <- lmer(ConPleasure ~ EEfRT_averaged_lowp + EEfRT_averaged_medp + EEfRT_averaged_highp + (1|subj_day) + (1|ID),  
                        data = ESM_merged, 
                        REML = FALSE, 
                        na.action = "na.omit", 
                        control = lmerControl(optimizer = "bobyqa"))

summary(test_ant_pl)
summary(test_con_pl)

```













